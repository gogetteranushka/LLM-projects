{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSv1uhoDwgb3Bk2wLm00N5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gogetteranushka/LLM-projects/blob/main/LLM_inference_with_Pre_Trained_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: To generate text using a small language model\n",
        "\n",
        "Model Chosen: distilgpt2"
      ],
      "metadata": {
        "id": "XRFlchon18rP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OolgANKd1mn1",
        "outputId": "50953cc6-9824-4577-f3c6-fc3eb7fc02bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "O76pM4WE2T1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator=pipeline(task=\"text-generation\", model=\"distilgpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "71gtOEwQ3kEi",
        "outputId": "40d637ba-3ca7-44b2-9e59-e90ec7e54c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output=generator(\"Today is a beautiful day\", max_length=30)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyxBujEH3uBU",
        "outputId": "da248d8c-bfd7-4325-cb18-aac26fbd3b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Today is a beautiful day and one that I am proud of.\\n\\nI would like to thank the staff at the North Fork Community Hospital for their help in preparing this event.\\nWe are thrilled to be a part of this exciting event, and I would highly consider doing so. I know that many of our guests will be in good spirits by the end of the day. The first time we met on the front porch was when I was going to a party at the corner of the street from the East River to the East River. We went there to celebrate a historic day at the North Fork Community Hospital for our family.\\nWe were looking forward to seeing you in the day.\\nThank you for your patronage and support.\\nThe North Fork Community Hospital is the best place for you to visit. We are so happy to have you all at North Fork.\\nPlease consider making a request to the North Fork Community Hospital for a visit.\\nWe are grateful to the people at the North Fork Community Hospital for their support in making an appointment to be with us.\\nWe want to thank everyone who has made this event possible.\\nThank you for your support and we look forward to seeing you again in the future.\\nThank you for your support and we look forward to seeing you again in'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output=generator(\"My name is Anushka. I am an introvert\", temperature=1, max_length=20)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbtXDlrx39sz",
        "outputId": "95f86f43-cf3e-418b-fc43-82db690ba627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'My name is Anushka. I am an introvert. I don\\'t know how I am going to get out. After all, I was always interested in finding out how to find out if a person you\\'ve talked to, or whether you love a good person is just an accident. It makes my head spin. One day I noticed I couldn\\'t find a person who lived with a girl in my life I would never believe. And now I have the words of my old acquaintance: \"For example, if I can find the girl I can identify and identify in what I know is real life, I have to choose.\" I have no idea how I like to interact with a girl who can identify and identify in my life. Why do I like her life? Because of that, it\\'s a bit difficult to identify with a person who exists in a manner that\\'s totally normal. If I find that he/she is a genuine, genuine person, then I can identify with her.\\n\\nThe problem with the word \"friend\" and \"friend\" is that many people have a bad relationship with an introvert. This does not always affect what people tell me about her: \"I\\'ve heard stories and heard stories about love songs, love songs, people singing together on a few days a week, and sometimes we get'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator(\"Today is a beautiful day\", max_length=30, temperature=0.1))\n",
        "print(generator(\"Today is a beautiful day\", max_length=30, temperature=1.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhk8hLNc4Xi2",
        "outputId": "1108e3db-4f13-46bd-f2a8-db8eabf74a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Today is a beautiful day.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]\n",
            "[{'generated_text': 'Today is a beautiful day. Today is a particularly rich day, and some beautiful dreams and things of the past. We will all spend the day living with these memories in the hope that we can somehow do the same.\\n\\nSo what you probably don\\'t know is that the dream is a very simple dream, but it involves very long and beautiful nights, as opposed to the normal \"dream\" of an ordinary person who seems destined to forget the past.\\nA dream often doesn\\'t exist at last in the dream. Sometimes it\\'s just like it\\'s so.\\nThe idea that it won\\'t last is even more complicated in this case.\\nThis is quite an interesting thought that I am looking ahead to next weekend when I am able to see the amazing dream that a person with special abilities can achieve. As for that dream at present, it only affects the most experienced and the most loved ones who really know the amazing dream.\\nAlso, the dream is that while things are easy to understand, there is an amazing way to actually understand it. You can think in more detail what the human mind means to be a person:\\n- the brain!\\n- all the brains!\\n- the brains!!!!\\xa0\\xa0\\xa0 * *\\nSome examples can still be found at Wikipedia:'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator(\"Today is a beautiful day\", max_length=30, top_k=10))\n",
        "print(generator(\"Today is a beautiful day\", max_length=30, top_k=100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6hg_ivXBjd2",
        "outputId": "c9b8e496-6d7d-4700-f22c-f8d935c76c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"Today is a beautiful day for our country. We have been together since the start of the year and it's been incredible to see the amazing things we have achieved.\\n\\n\\n\\nWe are very proud to announce that we are going to be hosting the first annual G-Day in the UK. We are proud to announce that we have partnered with the G-Day organisers in order to provide a special event for all our supporters. We are also proud to announce that there will be a G-day in our country, which will be held in the event of a new year.\\nWe are delighted to announce that the G-Day will be held in the UK. We will be hosting a special G-Day, with all our supporters.\\nAs we are planning an event, it is important to note that the G-Day is not an official event, but we hope to be able to offer a special event to all of us, including the G-Day.\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\nG-Day\\n\"}]\n",
            "[{'generated_text': 'Today is a beautiful day, and the people of the world are here to share it, and we will not let them down.\\n\\n\\n\\n\\n\\nThat’s right“\\nA big thank you to our employees for their long and hard work!\\nThank you to our sponsors, our sponsors, and our fans for signing up.\\nThanks to all of our sponsors, we are able to launch a new game, a new game, a new server, and more!\\nThank you for your support and your patience in supporting our team!'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator(\"Today is a beautiful day\", max_length=30, top_p=0.9))\n",
        "print(generator(\"Today is a beautiful day\", max_length=30, top_p=0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7E7XzPDBpoF",
        "outputId": "ff3f5650-6eb4-47fc-baef-1882483e539d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Today is a beautiful day in the world of photography. It’s not just about the images and the stories. It’s about the things that we do. We are all living in the same world we live in.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]\n",
            "[{'generated_text': 'Today is a beautiful day. It’s a wonderful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day. It’s a beautiful day'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimented with various temperatures, max_lengths, top_k, top_p words.\n",
        "\n",
        "Temperature: A parameter that controls the randomness and creativity in its text generation.\n",
        "\n",
        "Top_k words: It restricts the vocabulary to top k most likely words.\n",
        "\n",
        "Top_p: Only uses words whose probability of occurrence in a sentence sum up to p."
      ],
      "metadata": {
        "id": "MxINeJjRCkkW"
      }
    }
  ]
}
