{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnI/faj4AndwlXrTRS7uVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gogetteranushka/LLM-projects/blob/main/LLM_Semantic_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Given a query message like \"What is linear regression\", the system should return the most relevant text passage from a small corpus"
      ],
      "metadata": {
        "id": "L8y1jgWoToBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iCowlYQdE6Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae15f524-bf7f-4464-abf7-9c5b456b8b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "rL0zSQTxUGxa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigglist=[\"Big Data Analytics uses advanced analytical methods that can extract important business insights from bulk datasets. Within these datasets lies both structured (organized) and unstructured (unorganized) data.\", \"Big Data Analytics is all about crunching massive amounts of information to uncover hidden trends, patterns, and relationships. It's like sifting through a giant mountain of data to find the gold nuggets of insight.\",\"Analytics solutions glean insights and predict outcomes by analyzing data sets. However, in order for the data to be successfully analyzed, it must first be stored, organized, and cleaned by a series of applications in an integrated, step-by-step preparation process:\", \"Collect. The data, which comes in structured, semi-structured, and unstructured forms, is collected from multiple sources across web, mobile, and the cloud. It is then stored in a repository—a data lake or data warehouse—in preparation to be processed.\",\"Process. During the processing phase, the stored data is verified, sorted, and filtered, which prepares it for further use and improves the performance of queries. Scrub. After processing, the data is then scrubbed. Conflicts, redundancies, invalid or incomplete fields, and formatting errors within the data set are corrected and cleaned. Analyze. The data is now ready to be analyzed. Analyzing big data is accomplished through tools and technologies such as data mining, AI, predictive analytics, machine learning, and statistical analysis, which help define and predict patterns and behaviors in the data.\", \"Though it is often referred to as a single system or solution, big data analytics is actually composed of many individual technologies and tools working together to store, move, scale, and analyze data. They may vary depending on your infrastructure, but here are some of the most common big data analytics tools you'll find:\",\" Hadoop. One of the first frameworks to address the requirements of big data analytics, Apache Hadoop is an open-source ecosystem that stores and processes large data sets through a distributed computing environment. Hadoop can scale up or down, depending on your needs, which makes it a highly flexible and cost-efficient framework for managing big data.\", \"NoSQL databases. Unlike traditional databases, which are relational, NoSQL databases do not require that their data types adhere to a fixed schema or structure. This allows them to support all types of data models, which is useful when working with large quantities of semi-structured and raw data. Due to their flexibility, NoSQL databases have also proven to be faster and more scalable than relational databases. Some popular examples of NoSQL include MongoDB, Apache CouchDB, and Azure Cosmos DB..\", \"Data lakes and warehouses. Once data is collected from its sources, it must be stored in a central silo for further processing. A data lake holds raw and unstructured data, which is then ready to be used across applications, while a data warehouse is a system that pulls structured, pre-defined data from a variety of sources and processes that data for operational use. Both options have different functions, but they often work together to make up a well-organized system for data storage.\", \"Data integration software. Data integration tools connect and consolidate data from different platforms into one unified hub, such as a data warehouse, so that users have centralized access to all the information they need for data mining, business intelligence reporting, and operational purposes.\",\" In-memory data processing. While traditional data processing is disk-based, in-memory data processing uses RAM, or memory, to process data. This substantially increases processing and transfer speeds, making it possible for organizations to glean insights in real time. Processing frameworks like Apache Spark perform batch processing and real-time data stream processing in memory.\", \"Data preprocessing and scrubbing tools. To ensure that your data is of the highest quality, data cleansing tools resolve errors, fix syntax mistakes, remove missing values, and scrub duplicates. These tools then standardize and validate your data so that it's ready for analysis.\", \" Data mining. Big data analytics gain insight from data through knowledge discovery processes like data mining, which extracts underlying patterns from large data sets. Through algorithms designed to identify notable relationships between the data, data mining can automatically define current trends in data, both structured and unstructured.\", \" Predictive analytics. Predictive analytics helps build analytic models that predict patterns and behavior. This is accomplished through machine learning and other types of statistical algorithms, which allow you to identify future outcomes, improve operations, and meet the needs of your users.\", \" Real-time analytics. By connecting a series of scalable, end-to-end streaming pipelines, real-time streaming solutions like Azure Data Explorer store, process, and analyze your cross-platform data in real time, allowing you to gain insights instantly.\"]"
      ],
      "metadata": {
        "id": "KWrTkamYUObz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Embedding model that converts sentences to vectors"
      ],
      "metadata": {
        "id": "Ln55PtsxXP7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "PbAtVB3ZWsqE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "_VcjWDdKW3hJ"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modules.json: 100% 349/349 [00:00<00:00, 20.4kB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 8.04kB/s]\n",
            "README.md: 100% 10.5k/10.5k [00:00<00:00, 672kB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 4.21kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 56.5kB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:02<00:00, 52.7MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 26.8kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 4.90MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 13.4MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 11.3kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 16.9kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passage_embedding = model.encode(bigglist)"
      ],
      "metadata": {
        "id": "GHH2oWLrW1nD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = model.encode([\"What is big data analytics\"])"
      ],
      "metadata": {
        "id": "-dItVvMtXi_s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Es2Tv_u5Xpud"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5_lTlVQGbOSJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = cosine_similarity(query_embedding, passage_embedding)[0]\n",
        "\n",
        "# 6. Store results in a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    \"passage\": bigglist,\n",
        "    \"similarity\": similarities\n",
        "}).sort_values(by=\"similarity\", ascending=False)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKWNs9drXxlA",
        "outputId": "ab9e5543-d7c7-49f6-c939-63441e558c62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  passage  similarity\n",
            "1       Big Data Analytics is all about crunching mass...    0.802025\n",
            "5       Though it is often referred to as a single sys...    0.771461\n",
            "12      Data mining. Big data analytics gain insight ...    0.672828\n",
            "4       Process. During the processing phase, the stor...    0.660951\n",
            "0       Big Data Analytics uses advanced analytical me...    0.659630\n",
            "6        Hadoop. One of the first frameworks to addres...    0.612936\n",
            "2       Analytics solutions glean insights and predict...    0.534105\n",
            "13      Predictive analytics. Predictive analytics he...    0.458001\n",
            "9       Data integration software. Data integration to...    0.438216\n",
            "14      Real-time analytics. By connecting a series o...    0.436518\n",
            "10      In-memory data processing. While traditional ...    0.410396\n",
            "8       Data lakes and warehouses. Once data is collec...    0.374615\n",
            "7       NoSQL databases. Unlike traditional databases,...    0.319942\n",
            "3       Collect. The data, which comes in structured, ...    0.313598\n",
            "11   Data preprocessing and scrubbing tools. To ens...    0.284317\n"
          ]
        }
      ]
    }
  ]
}
